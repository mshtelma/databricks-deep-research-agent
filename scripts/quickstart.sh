#!/bin/bash
# Deep Research Agent - Local Development Quickstart
# Sets up local environment for development

set -e

echo "=============================================="
echo "Deep Research Agent - Quickstart Setup"
echo "=============================================="

# ============================================================================
# Prerequisites Check
# ============================================================================
echo ""
echo "[1/5] Checking prerequisites..."

MISSING_DEPS=()

if ! command -v databricks &> /dev/null; then
    MISSING_DEPS+=("databricks CLI (https://docs.databricks.com/dev-tools/cli/install.html)")
fi

if ! command -v uv &> /dev/null; then
    MISSING_DEPS+=("uv (curl -LsSf https://astral.sh/uv/install.sh | sh)")
fi

if ! command -v node &> /dev/null; then
    MISSING_DEPS+=("Node.js (https://nodejs.org/)")
fi

if ! command -v jq &> /dev/null; then
    MISSING_DEPS+=("jq (brew install jq or apt install jq)")
fi

if [ ${#MISSING_DEPS[@]} -gt 0 ]; then
    echo "ERROR: Missing prerequisites:"
    for dep in "${MISSING_DEPS[@]}"; do
        echo "  - $dep"
    done
    exit 1
fi

echo "All prerequisites installed"

# ============================================================================
# Databricks Authentication
# ============================================================================
echo ""
echo "[2/5] Setting up Databricks authentication..."

PROFILE_NAME="${DATABRICKS_CONFIG_PROFILE:-DEFAULT}"

if databricks current-user me --profile "$PROFILE_NAME" &> /dev/null; then
    echo "Already authenticated with profile: $PROFILE_NAME"
else
    echo "Authenticating with Databricks..."
    databricks auth login --profile "$PROFILE_NAME"
fi

DATABRICKS_USERNAME=$(databricks current-user me --profile "$PROFILE_NAME" | jq -r .userName)
DATABRICKS_HOST=$(databricks auth describe --profile "$PROFILE_NAME" 2>/dev/null | grep -oP 'Host:\s*\K.*' || echo "")
echo "Authenticated as: $DATABRICKS_USERNAME"

# ============================================================================
# MLflow Experiment Setup
# ============================================================================
echo ""
echo "[3/5] Setting up MLflow experiment..."

EXPERIMENT_PATH="/Workspace/Users/$DATABRICKS_USERNAME/deep-research-agent"
echo "Experiment path: $EXPERIMENT_PATH"

# Try to create or get existing experiment
EXPERIMENT_ID=$(databricks experiments create-experiment "$EXPERIMENT_PATH" --profile "$PROFILE_NAME" 2>/dev/null | jq -r '.experiment_id // empty' || echo "")

if [ -z "$EXPERIMENT_ID" ]; then
    # Experiment might already exist
    EXPERIMENT_ID=$(databricks experiments get-experiment --experiment-name "$EXPERIMENT_PATH" --profile "$PROFILE_NAME" 2>/dev/null | jq -r '.experiment.experiment_id // empty' || echo "")
fi

if [ -z "$EXPERIMENT_ID" ]; then
    echo "WARNING: Could not create/get MLflow experiment"
    echo "You may need to create it manually in the Databricks UI"
    EXPERIMENT_ID="<YOUR-EXPERIMENT-ID>"
else
    echo "MLflow Experiment ID: $EXPERIMENT_ID"
fi

# ============================================================================
# Install Dependencies
# ============================================================================
echo ""
echo "[4/5] Installing dependencies..."

echo "Installing Python dependencies..."
uv sync

echo "Installing frontend dependencies..."
cd frontend && npm install && cd ..

echo "Dependencies installed"

# ============================================================================
# Create .env.local
# ============================================================================
echo ""
echo "[5/5] Creating .env.local..."

cat > .env.local << ENVEOF
# Deep Research Agent - Local Development Configuration
# Generated by quickstart.sh on $(date -Iseconds)

# Databricks Authentication (profile-based)
DATABRICKS_CONFIG_PROFILE=$PROFILE_NAME

# MLflow Configuration
MLFLOW_EXPERIMENT_ID=$EXPERIMENT_ID
MLFLOW_TRACKING_URI=databricks

# App Configuration
APP_ENV=development
LOG_LEVEL=DEBUG
DEBUG=true

# Lakebase Configuration (update with your instance)
# LAKEBASE_INSTANCE_NAME=<your-lakebase-instance>
# LAKEBASE_DATABASE=deep_research

# Local PostgreSQL (alternative to Lakebase for development)
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/deep_research

# Brave Search API (required for web search)
# Get your key at: https://brave.com/search/api/
# BRAVE_API_KEY=<your-brave-api-key>

# CORS (for local development)
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# Frontend serving
SERVE_STATIC=false
ENVEOF

echo ".env.local created"

# ============================================================================
# Summary
# ============================================================================
echo ""
echo "=============================================="
echo "Setup Complete!"
echo "=============================================="
echo ""
echo "Next steps:"
echo ""
echo "1. Update .env.local with your settings:"
echo "   - LAKEBASE_INSTANCE_NAME (or use local PostgreSQL)"
echo "   - BRAVE_API_KEY (get from https://brave.com/search/api/)"
echo ""
echo "2. Start local PostgreSQL (optional):"
echo "   make db"
echo ""
echo "3. Start development server:"
echo "   make dev"
echo ""
echo "4. Access the app at: http://localhost:5173"
echo ""
echo "For production deployment:"
echo "   make deploy TARGET=dev BRAVE_SCOPE=<your-scope>"
echo ""
