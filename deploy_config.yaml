# Databricks Deployment Configuration
# This file defines environment-specific settings for the LangGraph agent deployment

# Global settings
global:
  project_name: "langgraph-research-agent"
  local_source_path: "./deep_research_agent"  # Source code location
  
  # Sync settings
  sync:
    exclude_patterns:
      - "*.pyc"
      - "__pycache__/"
      - ".git/"
      - "*.log"
      - ".DS_Store"
      - "*.pytest_cache"
    include_patterns:
      - "*.py"
      - "*.ipynb"
      - "*.yaml"
      - "*.yml"
      - "*.txt"
      - "*.md"

# Environment configurations
environments:
  dev:
    profile: "e2-demo-west"  # Databricks CLI profile name
    workspace_path: "/Workspace/Users/michael.shtelma@databricks.com/LLM/langgraph-research-agent"
    
    # Model configuration
    model:
      catalog: "main"
      schema: "msh"
      name: "langgraph_research_agent_dev"
      
    # Serving endpoint configuration
    endpoint:
      name: "langgraph-research-agent-dev"
      workload_size: "Small"
      scale_to_zero: true
      
    # Job configuration
    job:
      name: "LangGraph Agent Deployment - Dev"
      timeout_seconds: 1800  # 30 minutes
      max_retries: 1
      email_notifications: []
      
      # Use existing interactive cluster
      existing_cluster_id: "0816-235658-5i3k9jfh"
      
    # Auto-capture configuration
    auto_capture_config:
      catalog_name: "main"
      schema_name: "msh"
      table_name_prefix: "langgraph_agent"

  staging:
    profile: "e2-demo-field-eng"
    workspace_path: "/Workspace/Shared/langgraph-agent/staging"
    
    # Model configuration
    model:
      catalog: "main"
      schema: "staging_app"
      name: "langgraph_research_agent_staging"
      
    # Serving endpoint configuration
    endpoint:
      name: "langgraph-research-agent-staging"
      workload_size: "Small"
      scale_to_zero: true
      
    # Job configuration
    job:
      name: "LangGraph Agent Deployment - Staging"
      timeout_seconds: 2400  # 40 minutes
      max_retries: 2
      email_notifications:
        - "team@example.com"
      
      # Use existing interactive cluster for staging too
      existing_cluster_id: "0816-235658-5i3k9jfh"
        
    # Auto-capture configuration
    auto_capture_config:
      catalog_name: "main"
      schema_name: "staging_app"
      table_name_prefix: "langgraph_agent"

  prod:
    profile: "e2-demo-field-eng"
    workspace_path: "/Workspace/Shared/langgraph-agent/prod"
    
    # Model configuration
    model:
      catalog: "main"
      schema: "app"
      name: "langgraph_research_agent"
      
    # Serving endpoint configuration
    endpoint:
      name: "langgraph-research-agent"
      workload_size: "Medium"
      scale_to_zero: false
      
    # Job configuration
    job:
      name: "LangGraph Agent Deployment - Production"
      timeout_seconds: 3600  # 60 minutes
      max_retries: 2
      email_notifications:
        - "team@example.com"
        - "oncall@example.com"
      
      # Create dedicated cluster for production
      new_cluster:
        spark_version: "13.3.x-scala2.12"
        node_type_id: "i3.2xlarge"
        num_workers: 2
        spark_env_vars:
          ENVIRONMENT: "production"
        
    # Auto-capture configuration
    auto_capture_config:
      catalog_name: "main"
      schema_name: "app"
      table_name_prefix: "langgraph_agent"

  test:
    profile: "e2-demo-field-eng"
    workspace_path: "/Workspace/Shared/langgraph-agent/test"
    
    # Model configuration
    model:
      catalog: "main"
      schema: "test_app"
      name: "langgraph_research_agent_test"
      
    # Serving endpoint configuration
    endpoint:
      name: "langgraph-research-agent-test"
      workload_size: "Small"
      scale_to_zero: true
      
    # Job configuration - NO COMPUTE CONFIG = SERVERLESS
    job:
      name: "LangGraph Agent Deployment - Test"
      timeout_seconds: 1800
      max_retries: 1
      email_notifications: []
        
    # Auto-capture configuration
    auto_capture_config:
      catalog_name: "main"
      schema_name: "test_app"
      table_name_prefix: "langgraph_agent"

# Secret scopes and keys
secrets:
  scope: "langgraph-app"
  keys:
    tavily_api_key: "TAVILY_API_KEY"
    databricks_token: "DATABRICKS_TOKEN"

# Agent configuration is now centralized in deep_research_agent/agent_config.yaml
# This eliminates the need for model_defaults here - the YAML configuration
# travels with the model and provides a single source of truth

# Vector search configuration (optional)
vector_search:
  enabled: false
  index_name: "main.default.docs_index"
  
# Monitoring and alerting
monitoring:
  enable_inference_table: true
  enable_review_ui: true

# Compute behavior:
# - If job has "existing_cluster_id" -> use that existing cluster
# - If job has "new_cluster" -> create new cluster with that config
# - If neither -> use serverless compute (default)