# LangGraph Research Agent Configuration
# This file contains all agent configuration parameters including LLM settings,
# research behavior, rate limiting, and tool configurations.

# Model Configuration with per-model parameters
models:
  default:
    endpoint: "databricks-gpt-oss-120b"
    temperature: 0.7
    max_tokens: 4000
    
  query_generation:
    endpoint: "databricks-gpt-oss-20b"
    temperature: 0.5  # Lower temperature for more focused queries
    max_tokens: 2000
    
  web_research:
    endpoint: "databricks-gpt-oss-20b"
    temperature: 0.7
    max_tokens: 4000
    
  reflection:
    endpoint: "databricks-gpt-oss-120b"
    temperature: 0.8  # Higher temperature for creative reflection
    max_tokens: 3000
    
  synthesis:
    endpoint: "databricks-gpt-oss-120b"
    temperature: 0.7
    max_tokens: 6000  # More tokens for comprehensive synthesis
    
  embedding:
    endpoint: "databricks-gte-large-en"
    # No generation parameters needed for embedding

# Research Behavior Configuration  
research:
  max_research_loops: 1
  initial_query_count: 2
  enable_streaming: true
  enable_citations: true
  timeout_seconds: 30
  max_retries: 3
  search_provider: "brave"  # Options: "tavily" or "brave"

# Rate Limiting and Batch Processing Configuration
rate_limiting:
  max_concurrent_searches: 1      # Max parallel API calls per batch
  batch_delay_seconds: 2.0        # Delay between searches (increase to 3-5 for Brave if rate limited)

# Tool Configurations
tools:
  tavily_search:
    enabled: false
    api_key: "{{secrets/msh/TAVILY_API_KEY}}"  # MLflow secret reference
    base_url: "https://api.tavily.com"
    search_depth: "advanced"
    max_results: 5
    timeout_seconds: 30
    max_retries: 3

  brave_search:
    enabled: true  # Enable to use Brave Search instead of Tavily
    api_key: "{{secrets/msh/BRAVE_API_KEY}}"  # MLflow secret reference
    base_url: "https://api.search.brave.com/res/v1"
    max_results: 5
    timeout_seconds: 30
    max_retries: 3

  vector_search:
    enabled: false  # Enable if vector search is available
    index_name: "main.default.docs_index"
    text_column: "content"
    columns: ["source", "title", "url"]
    k: 5
    timeout_seconds: 30

  python_exec:
    enabled: true
    function_names: ["system.ai.python_exec"]
    timeout_seconds: 30

# Databricks Configuration
databricks:
  workspace_url: null  # Set via DATABRICKS_HOST or DATABRICKS_WORKSPACE_URL env vars
  token: null          # Set via DATABRICKS_TOKEN env var

# Environment-specific Overrides
# These can be used to customize behavior per environment
environments:
  dev:
    research:
      max_research_loops: 1  # Faster for development
    rate_limiting:
      max_concurrent_searches: 1  # Conservative for dev
  
  staging:
    rate_limiting:
      max_concurrent_searches: 2
      batch_delay_seconds: 1.5

  prod:
    rate_limiting:
      max_concurrent_searches: 3  # More aggressive for production
      batch_delay_seconds: 0.5
    research:
      max_research_loops: 3  # More thorough research in prod

# Validation Rules
# These define valid ranges for configuration values
validation:
  models:
    temperature:
      min: 0.0
      max: 2.0
    max_tokens:
      min: 100
      max: 8000
  
  research:
    max_research_loops:
      min: 1
      max: 5
    initial_query_count:
      min: 1
      max: 10
  
  rate_limiting:
    max_concurrent_searches:
      min: 1
      max: 10
    batch_delay_seconds:
      min: 0.0
      max: 10.0

# Schema version for compatibility checking
schema_version: "1.0"
created_date: "2025-08-22"
description: "Centralized configuration for LangGraph Research Agent with batch processing"