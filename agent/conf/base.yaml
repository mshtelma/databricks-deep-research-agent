# Deep Research Agent Configuration
# This is the comprehensive base configuration for the multi-agent research system.
# Only includes parameters that are actually used in the codebase.

# Model Configuration - 4-Tier System with Rate Limiting
models:
  default:
    endpoint: gpt-oss-20b
    temperature: 0.7
    max_tokens: 16000
    reasoning_effort: low

  # TIER 1: MICRO - Ultra-lightweight (pattern matching, entity extraction)
  micro:
    endpoints:
      - gpt-oss-20b  # Highest priority (most throughput)
      - databricks-gemma-3-12b
      - databricks-meta-llama-3-1-8b-instruct
    temperature: 0.5
    max_tokens: 4000
    tokens_per_minute: 800000  # Higher limit for lightweight model
    rotation_strategy: priority  # CHANGED: Priority-based (config order = priority order)
    fallback_on_429: true  # Single endpoint

  # TIER 2: SIMPLE - Lightweight (query gen, claim extraction, validation)
  simple:
    endpoints:
      - gpt-oss-20b  # Highest priority (most throughput)
      - databricks-gpt-oss-20b
      - databricks-llama-4-maverick
      - databricks-meta-llama-3-3-70b-instruct
    temperature: 0.5
    max_tokens: 8000
    reasoning_effort: low
    tokens_per_minute: 50000  # Medium rate limit
    rotation_strategy: priority  # CHANGED: Priority-based (config order = priority order)
    fallback_on_429: true  # Single endpoint

  # TIER 3: ANALYTICAL - Medium (research synthesis, fact checking, planning)
  analytical:
    endpoints:
      - gpt-oss-120b  # Highest priority (most throughput)
      - databricks-gpt-oss-120b
      - databricks-llama-4-maverick
      - databricks-meta-llama-3-3-70b-instruct
    temperature: 0.7
    max_tokens: 12000
    reasoning_effort: medium
    tokens_per_minute: 100000  # Provisioned throughput limit
    rotation_strategy: priority  # CHANGED: Priority-based (config order = priority order)
    fallback_on_429: true  # Enable fallback to second endpoint

  # TIER 4: COMPLEX - Heavy (report generation, complex tables, synthesis)
  complex:
    endpoints:
      - gpt-oss-120b  # Highest priority (most throughput)
      - databricks-gpt-oss-120b
      - databricks-claude-sonnet-4
      - databricks-claude-3-7-sonnet
    temperature: 0.7
    max_tokens: 32000
    reasoning_effort: high
    reasoning_budget: 8000
    tokens_per_minute: 100000  # Higher PT limit for powerful model
    rotation_strategy: priority  # CHANGED: Priority-based (config order = priority order)
    fallback_on_429: true  # Single powerful endpoint



# Multi-Agent System Configuration
multi_agent:
  enabled: true

agents:
  coordinator:
    enabled: true
    model: simple  # Use simple model for classification
    enable_safety_filter: true

  planner:
    enabled: true
    model: analytical  # Use analytical model for planning
    max_iterations: 2
    quality_threshold: 0.5
    enable_deep_thinking: false

  researcher:
    enabled: true
    model: analytical  # Use analytical model for research
    max_steps_per_execution: 20  # Increased for complex multi-country comparisons
    enable_reflexion: true

  fact_checker:
    enabled: true
    model: analytical  # Use analytical model for fact checking
    verification_level: strict
    enable_contradiction_detection: true

  reporter:
    enabled: true
    model: complex  # Use complex model for final synthesis
    default_style: default
    citation_style: APA
    enable_grounding_markers: true
    use_semantic_extraction: true
    # Structured generation (NEW - guarantees JSON structure, not markdown syntax!)
    enable_structured_generation: true  # Use Pydantic models + programmatic rendering
    structured_generation_fallback: false  # CHANGED: Enable fallback to prevent "Error: Structured generation failed" messages when rate limited
    # Table validation MUST stay enabled - structured generation doesn't validate markdown!
    enable_table_validation: true  # POST-PROCESS to fix missing separator rows
    enable_llm_self_correction: false  # LLM correction is overkill, validation is enough
    max_correction_retries: 3  # CHANGED: More retry attempts before falling back (was 1)

# Search Configuration
search:
  providers:
    brave:
      enabled: true
      # api_key loaded from BRAVE_API_KEY environment variable
      max_results: 20
      rate_limit: 1
      timeout: 30
    tavily:
      enabled: false
      # api_key loaded from TAVILY_API_KEY environment variable
      max_results: 10
      rate_limit: 1
      timeout: 30
  max_concurrent_searches: 3
  batch_delay_seconds: 1.0
  max_results_per_query: 20
  enable_safe_search: true

# Global recursion limit (mirrors workflow setting for components that read top-level key)
recursion_limit: 400

# Workflow Configuration
workflow:
  max_research_loops: 1  # Increased for very complex multi-country research
  max_fact_check_loops: 1  # Increased for better verification
  max_total_steps: 150  # Increased for complex multi-country workflows
  max_wall_clock_seconds: 2400  # Increased to 40 minutes for very complex queries
  recursion_limit: 400  # Increased for complex adaptive structures
  enable_background_investigation: true
  enable_human_feedback: false
  auto_accept_plan: false
  enable_circuit_breakers: true
  enable_progress_tracking: true

# Rate Limiting Configuration - Comprehensive System
rate_limiting:
  enabled: true  # Master switch for entire rate limiting system

  # Retry Strategy (exponential backoff with jitter) - TUNED FOR 429 ERRORS
  retry:
    base_delay_seconds: 15.0  # CHANGED: Start with 15s delay (was 5.0) - respect 429 cooldowns
    max_delay_seconds: 120.0  # CHANGED: Cap at 120s (was 30.0) - allow longer exponential backoff
    max_retries: 8  # CHANGED: Up to 8 retry attempts (was 5) - more patience
    jitter: 0.5  # CHANGED: Â±50% randomization (was 0.3) - prevent synchronized retries

  # Request Coordination (prevent bursts) - SERIALIZE TO PREVENT 429s
  coordination:
    max_concurrent_per_endpoint: 1  # CHANGED: Max 1 request per endpoint (was 2) - serialize to prevent bursts

  # Cooldown After 429 Errors - LONGER WAITS
  cooldown:
    default_cooldown_seconds: 30  # CHANGED: 30s cooldown after 429 (was 10s) - respect provisioned throughput limits
    respect_retry_after_header: true  # Use Retry-After header if present

  # Token Budget Tracking
  token_tracking:
    enable_sliding_window: true  # Use sliding window for token counting
    window_seconds: 60  # Track tokens over 60s window
    safety_margin: 0.9  # Use only 90% of declared limit

  # Phase Delays (strategic pauses between pipeline stages) - MORE SPACING
  phase_delays:
    after_research_before_fact_check: 8.0  # CHANGED: 8s pause after research (was 3.0)
    after_fact_check_before_report: 12.0  # CHANGED: 12s pause before reporting (was 5.0)
    between_section_generations: 5.0  # CHANGED: 5s between each report section (was 2.0) - CRITICAL for preventing 429s during report generation

# Tier Fallback Configuration
tier_fallback:
  enable_cross_tier_fallback: true  # Allow falling back to lower tiers when rate limited
  fallback_chain:
    complex: analytical      # Complex can fall back to analytical
    analytical: simple       # Analytical can fall back to simple
    simple: micro           # Simple can fall back to micro
    micro: null             # Micro has no fallback (last resort)


# Grounding and Factuality Configuration
grounding:
  enable_grounding: true
  verification_level: strict
  enable_contradiction_detection: true
  factuality_threshold: 0.6

# Entity Validation Configuration
entity_validation:
  enabled: true
  validation_mode: strict  # strict, moderate, lenient
  enable_synthesis_validation: true
  enable_observation_validation: true
  enable_section_validation: true
  track_violations: true

# Reflexion Configuration
reflexion:
  enable_reflexion: true
  reflection_memory_size: 50

# Streaming Configuration
streaming:
  enable_streaming: true
  max_events_per_second: 20
  batch_events: false  # Disabled for real-time event delivery
  batch_size: 1        # Send events individually  
  batch_timeout_ms: 50 # Minimum allowed value (but batching is disabled)

# Citations Configuration
citations:
  citation_style: APA
  enable_citations: true
  max_citations_per_section: 30

# Report Configuration
report:
  default_style: default  # Enable adaptive structure by using DEFAULT style
  enable_grounding_markers: true
  citation_style: APA

# Quality Enhancement Configuration
quality_enhancement:
  enabled: true
  detect_redundancy: true
  eliminate_redundancy: true
  optimize_structure: true

# Adaptive Structure Configuration
adaptive_structure:
  enable_adaptive_structure: true  # Disabled - causes section dependency issues
  adaptive_structure_cache_ttl: 3600  # Cache structures for 1 hour
  use_llm_for_structure: true  # Use LLM to generate creative section names
  max_structure_sections: 8  # Maximum number of sections
  min_structure_sections: 4  # Minimum number of sections

# Memory and State Management Configuration
memory:
  max_observations: 100  # Increased for comprehensive research (was hardcoded to 20)
  max_observations_per_step: 50  # Per-step observation limit (was hardcoded to 10)
  max_search_results: 100  # Search result accumulation limit (was hardcoded to 50)

