"""
Report generation debugging utility.

Logs report evolution through all hybrid generation stages for analysis.
Enable with: REPORTER_DEBUG=true

Debug logs are stored in: ./log/reporter_debug/
"""

import json
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional


class ReportDebugLogger:
    """
    Logs report transformation through all generation stages.

    Creates markdown files for each stage showing:
    - Full content (no truncation)
    - Metadata (tokens, model, timing)
    - Analysis (header count, table count, anchors)
    - Diffs between stages
    """

    def __init__(self, debug_dir: str = "./log/reporter_debug"):
        """
        Initialize debug logger.

        Args:
            debug_dir: Directory to save debug files (default: ./log/reporter_debug)
        """
        self.debug_dir = Path(debug_dir)
        self.debug_dir.mkdir(parents=True, exist_ok=True)

        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.stage_counter = 0
        self.stages: List[Dict] = []

    def log_stage(
        self,
        stage_name: str,
        content: Any,
        metadata: Optional[Dict] = None
    ) -> None:
        """
        Log a generation stage with full content and analysis.

        Args:
            stage_name: Descriptive name (e.g., "phase2_raw_output")
            content: The content at this stage (report text, JSON, etc.)
            metadata: Optional metadata dict (model, timing, etc.)
        """
        self.stage_counter += 1
        content_str = str(content)

        # Build filename
        safe_name = re.sub(r'[^\w\-]', '_', stage_name.lower())
        filename = f"{self.session_id}_stage_{self.stage_counter:02d}_{safe_name}.md"
        filepath = self.debug_dir / filename

        # Analyze content
        analysis = self._analyze_content(content_str)

        # Save stage info for summary
        self.stages.append({
            'number': self.stage_counter,
            'name': stage_name,
            'filename': filename,
            'length': len(content_str),
            'analysis': analysis,
            'metadata': metadata or {}
        })

        # Write markdown file
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# Stage {self.stage_counter}: {stage_name}\n\n")
            f.write(f"**Timestamp**: {datetime.now().isoformat()}\n")
            f.write(f"**Length**: {len(content_str):,} characters\n")
            f.write(f"**File**: `{filename}`\n\n")

            # Metadata section
            if metadata:
                f.write("## Metadata\n\n")
                f.write("```json\n")
                f.write(json.dumps(metadata, indent=2, default=str))
                f.write("\n```\n\n")

            # Analysis section
            f.write("## Content Analysis\n\n")
            f.write(f"- **Headers (`##`)**: {analysis['header_count']}\n")
            f.write(f"- **Headers (`###`)**: {analysis['h3_count']}\n")
            f.write(f"- **Table rows**: {analysis['table_rows']}\n")
            f.write(f"- **Table anchors**: {analysis['table_anchors']}\n")
            f.write(f"- **Separator rows**: {analysis['separator_rows']}\n")
            f.write(f"- **Lines**: {analysis['line_count']}\n\n")

            if analysis['table_anchors'] > 0:
                f.write(f"  - **Anchor IDs**: {', '.join(analysis['anchor_ids'])}\n\n")

            # Full content section
            f.write("## Full Content\n\n")
            f.write("```markdown\n")
            f.write(content_str)
            f.write("\n```\n\n")

            # Visual dividers for readability
            f.write("---\n\n")
            f.write("_Debug log generated by ReportDebugLogger_\n")

        print(f"[DEBUG] Logged stage {self.stage_counter}: {stage_name} → {filepath}")

    def _analyze_content(self, content: str) -> Dict:
        """
        Analyze content structure.

        Args:
            content: Text to analyze

        Returns:
            Dict with counts and patterns
        """
        # Count various patterns
        header_count = len(re.findall(r'^##\s+', content, re.MULTILINE))
        h3_count = len(re.findall(r'^###\s+', content, re.MULTILINE))
        table_rows = len(re.findall(r'\|.*\|.*\|', content))
        separator_rows = len(re.findall(r'\|[-:]+\|', content))
        line_count = content.count('\n')

        # Extract table anchor IDs
        anchor_matches = re.findall(r'\[TABLE:\s*([^\]]+)\]', content, re.IGNORECASE)

        return {
            'header_count': header_count,
            'h3_count': h3_count,
            'table_rows': table_rows,
            'table_anchors': len(anchor_matches),
            'anchor_ids': anchor_matches,
            'separator_rows': separator_rows,
            'line_count': line_count
        }

    def create_summary(self) -> None:
        """
        Create a summary index file showing all stages and changes.
        """
        summary_path = self.debug_dir / f"{self.session_id}_index.md"

        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(f"# Report Generation Debug Log\n\n")
            f.write(f"**Session**: {self.session_id}\n")
            f.write(f"**Stages**: {self.stage_counter}\n")
            f.write(f"**Generated**: {datetime.now().isoformat()}\n\n")

            f.write("## Stage Summary\n\n")
            f.write("| # | Stage | Length | ##Headers | Tables | Anchors | File |\n")
            f.write("|---|-------|--------|-----------|--------|---------|------|\n")

            for stage in self.stages:
                f.write(f"| {stage['number']} ")
                f.write(f"| {stage['name']} ")
                f.write(f"| {stage['length']:,} ")
                f.write(f"| {stage['analysis']['header_count']} ")
                f.write(f"| {stage['analysis']['table_rows']} ")
                f.write(f"| {stage['analysis']['table_anchors']} ")
                f.write(f"| [{stage['filename']}]({stage['filename']}) |\n")

            # Analyze changes between stages
            f.write("\n## Key Changes Between Stages\n\n")
            for i in range(len(self.stages) - 1):
                prev = self.stages[i]
                curr = self.stages[i + 1]

                header_change = curr['analysis']['header_count'] - prev['analysis']['header_count']
                table_change = curr['analysis']['table_rows'] - prev['analysis']['table_rows']
                anchor_change = curr['analysis']['table_anchors'] - prev['analysis']['table_anchors']

                if header_change != 0 or table_change != 0 or anchor_change != 0:
                    f.write(f"### {prev['name']} → {curr['name']}\n\n")

                    if header_change != 0:
                        f.write(f"- Headers: {prev['analysis']['header_count']} → "
                               f"{curr['analysis']['header_count']} "
                               f"({header_change:+d})\n")
                    if table_change != 0:
                        f.write(f"- Table rows: {prev['analysis']['table_rows']} → "
                               f"{curr['analysis']['table_rows']} "
                               f"({table_change:+d})\n")
                    if anchor_change != 0:
                        f.write(f"- Anchors: {prev['analysis']['table_anchors']} → "
                               f"{curr['analysis']['table_anchors']} "
                               f"({anchor_change:+d})\n")

                    f.write("\n")

            # Critical issues
            f.write("\n## Critical Issues Detected\n\n")
            issues = []

            # Check if headers disappeared
            max_headers = max(s['analysis']['header_count'] for s in self.stages)
            final_headers = self.stages[-1]['analysis']['header_count']
            if final_headers < max_headers:
                issues.append(f"⚠️ Headers decreased from {max_headers} to {final_headers}")

            # Check if anchors never resolved
            final_anchors = self.stages[-1]['analysis']['table_anchors']
            if final_anchors > 0:
                issues.append(f"⚠️ {final_anchors} unresolved table anchors in final output")

            if issues:
                for issue in issues:
                    f.write(f"- {issue}\n")
            else:
                f.write("No critical issues detected.\n")

            f.write("\n---\n\n")
            f.write(f"_Generated by ReportDebugLogger • Session: {self.session_id}_\n")

        print(f"\n[DEBUG] Summary created: {summary_path}")
        print(f"[DEBUG] View all logs: ls {self.debug_dir}/{self.session_id}_*")
