# Deep Research Agent - Test Configuration
# Minimal settings for fast integration tests
# Used by: tests/integration/ (set via APP_CONFIG_PATH env var)

# Use fastest model tier by default
default_role: simple

# Model endpoint definitions (same as production)
endpoints:
  haiku:
    endpoint_identifier: databricks-claude-haiku-4-5
    max_context_window: 32000  # Reduced for tests
    tokens_per_minute: 50000
    supports_structured_output: true

  gpt5nano:
    endpoint_identifier: databricks-gpt-5-nano
    max_context_window: 32000
    tokens_per_minute: 50000
    supports_structured_output: true
    supports_temperature: false

  gemini3flash:
    endpoint_identifier: databricks-gemini-3-flash
    max_context_window: 32000
    tokens_per_minute: 50000
    supports_structured_output: true

# Model roles - lower token limits for speed
models:
  simple:
    endpoints:
      - haiku
      - gpt5nano
      - gemini3flash
    temperature: 0.3  # More deterministic for tests
    max_tokens: 2000  # Reduced for speed
    reasoning_effort: low
    tokens_per_minute: 50000
    rotation_strategy: priority
    fallback_on_429: true

  analytical:
    endpoints:
      - haiku
      - gpt5nano
      - gemini3flash
    temperature: 0.3
    max_tokens: 4000
    reasoning_effort: medium
    tokens_per_minute: 50000
    rotation_strategy: priority
    fallback_on_429: true

  complex:
    endpoints:
      - haiku  # Use haiku instead of sonnet for tests
    temperature: 0.3
    max_tokens: 8000
    reasoning_effort: medium
    tokens_per_minute: 50000
    rotation_strategy: priority
    fallback_on_429: true

# Agent configuration - minimal for fast tests
agents:
  researcher:
    max_search_queries: 1        # Minimal searches
    max_search_results: 5        # Fewer results
    max_urls_to_crawl: 2         # Minimal crawling
    content_preview_length: 1000
    content_storage_length: 5000
    max_previous_observations: 2
    page_contents_limit: 3000
    max_generated_queries: 2

  planner:
    max_plan_iterations: 1       # Single iteration

  coordinator:
    max_clarification_rounds: 1
    enable_clarification: false  # Skip clarification in tests

  synthesizer:
    max_report_length: 10000     # Shorter reports

  background:
    max_search_queries: 1
    max_results_per_query: 2
    max_total_results: 3

# Research Type Profiles - minimal settings for tests
# All types use ReAct mode for realistic testing with limited tool calls
research_types:
  light:
    steps:
      min: 1
      max: 2
      prompt_guidance: "Quick overview with 1-2 focused steps."
    report_limits:
      min_words: 300
      max_words: 600
      max_tokens: 1200
    researcher:
      mode: react
      max_search_queries: 2
      max_urls_to_crawl: 2
      max_tool_calls: 5
    citation_verification:
      generation_mode: natural
      enable_numeric_qa_verification: false

  medium:
    steps:
      min: 2
      max: 3
      prompt_guidance: "Balanced research, 2-3 steps."
    report_limits:
      min_words: 500
      max_words: 1000
      max_tokens: 2000
    researcher:
      mode: react
      max_search_queries: 3
      max_urls_to_crawl: 3
      max_tool_calls: 8
    citation_verification:
      generation_mode: natural

  extended:
    steps:
      min: 3
      max: 4
      prompt_guidance: "Thorough research for testing."
    report_limits:
      min_words: 800
      max_words: 1500
      max_tokens: 3000
    researcher:
      mode: react
      max_search_queries: 4
      max_urls_to_crawl: 4
      max_tool_calls: 12
    citation_verification:
      generation_mode: natural
      enable_numeric_qa_verification: false

# Search configuration
search:
  brave:
    requests_per_second: 1.0
    default_result_count: 5      # Fewer results
    freshness: pm

# Rate limiting
rate_limiting:
  max_retries: 2
  base_delay_seconds: 1.0
  max_delay_seconds: 30.0
  backoff_strategy: exponential
  jitter: true

# Truncation limits
truncation:
  log_preview: 200
  error_message: 500
  query_display: 100
  source_snippet: 300

# Citation verification - enabled but with minimal settings
citation_verification:
  enabled: true

  # Synthesis mode: controls the overall synthesis approach
  # - "interleaved": Current approach - evidence in context, [N] markers
  # - "react": ReAct-based - LLM uses tools to retrieve evidence before claims
  synthesis_mode: react

  # Generation mode for research reports (only applies when synthesis_mode=interleaved)
  # - "classical": Free-form prose with inline [Title](url) links
  #                Best text quality, uses existing synthesizer
  #                Skips verification stages 3-6 (no claim markers to verify)
  # - "natural": Light-touch [N] citations, balanced quality + verification
  #              Good text quality while maintaining verifiable citations
  #              Runs full verification pipeline (stages 3-6)
  # - "strict": Heavy [N] constraints, maximum citations (DEFAULT)
  #             Current behavior, every claim must cite evidence
  #             Runs full verification pipeline (stages 3-6)
  generation_mode: natural

  # ReAct synthesis configuration (only applies when synthesis_mode=react)
  react_synthesis:
    max_tool_calls: 40              # Total tool call budget
    tool_budget_per_section: 10     # Budget per research step section
    retrieval_window_size: 3        # Sliding window for grounding inference
    grounding_threshold: 0.6        # Minimum similarity for grounded claim
    embedding_high_threshold: 0.7   # Auto-grounded above this
    embedding_low_threshold: 0.4    # Auto-ungrounded below this
    use_llm_judge_for_borderline: true  # Use LLM for 0.4-0.7 range
    enable_post_processing: true    # Polish pass for coherence
    use_sectioned_synthesis: false  # Disabled to use XML tag parsing in run_react_synthesis()

  enable_evidence_preselection: true
  enable_interleaved_generation: true
  enable_confidence_classification: true
  enable_citation_correction: true
  enable_numeric_qa_verification: true
  enable_verification_retrieval: false

  evidence_preselection:
    max_spans_per_source: 5      # Reduced
    min_span_length: 50
    max_span_length: 300         # Reduced
    relevance_threshold: 0.3
    numeric_content_boost: 0.2
    relevance_computation_method: hybrid

  interleaved_generation:
    max_claims_per_section: 5    # Reduced
    min_evidence_similarity: 0.5
    retry_on_entailment_failure: false  # No retries in tests
    max_retries: 1

  confidence_classification:
    high_threshold: 0.85
    low_threshold: 0.50
    quote_match_bonus: 0.3
    hedging_word_penalty: 0.2
    estimation_method: linguistic

  isolated_verification:
    enable_nei_verdict: true
    verification_model_tier: simple    # Use simple tier
    quick_verification_tier: simple

  citation_correction:
    correction_method: keyword_semantic_hybrid
    lambda_weight: 0.8
    correction_threshold: 0.6
    allow_alternate_citations: true

  numeric_qa_verification:
    rounding_tolerance: 0.05
    answer_comparison_method: f1
    require_unit_match: true
    require_entity_match: true

  verification_retrieval:
    trigger_on_verdicts: [unsupported, nei]
    max_additional_searches: 1
    search_timeout_seconds: 2

  unsupported_claim_warning_threshold: 0.20
