# Deep Research Agent - Central Configuration
# This file configures model endpoints, roles, agent limits, and search settings.
# Secrets should use environment variables: ${ENV_VAR} or ${ENV_VAR:-default}

# Default model role used when no specific role is requested
default_role: analytical

# Model endpoint definitions
# Each endpoint must have: endpoint_identifier, max_context_window, tokens_per_minute
endpoints:
  haiku:
    endpoint_identifier: databricks-claude-haiku-4-5
    max_context_window: 128000
    tokens_per_minute: 50000
    supports_structured_output: true

  gpt5nano:
    endpoint_identifier: databricks-gpt-5-nano
    max_context_window: 128000
    tokens_per_minute: 50000
    supports_structured_output: true
    supports_temperature: false  # GPT-5 models don't support temperature parameter

  gpt5mini:
    endpoint_identifier: databricks-gpt-5-mini
    max_context_window: 128000
    tokens_per_minute: 50000
    supports_structured_output: true
    supports_temperature: false  # GPT-5 models don't support temperature parameter

  gemini3flash:
    endpoint_identifier: databricks-gemini-3-flash
    max_context_window: 128000
    tokens_per_minute: 50000
    supports_structured_output: true

  sonnet:
    endpoint_identifier: databricks-claude-sonnet-4-5
    max_context_window: 128000
    tokens_per_minute: 50000
    supports_structured_output: true

# Model roles (tiers) with priority-ordered endpoints
# Endpoints are tried in order; fallback occurs on 429 or 5xx errors
models:
  # TIER 1: SIMPLE - Lightweight operations (query gen, validation)
  simple:
    endpoints:
      - haiku
      - gemini3flash
    temperature: 0.7
    max_tokens: 8000
    reasoning_effort: low
    tokens_per_minute: 200000
    rotation_strategy: priority
    fallback_on_429: true

  # TIER 2: ANALYTICAL - Medium operations (research, planning)
  analytical:
    endpoints:
      - haiku
      - gpt5mini
      - gemini3flash
    temperature: 0.7
    max_tokens: 8000
    reasoning_effort: medium
    tokens_per_minute: 200000
    rotation_strategy: priority
    fallback_on_429: true

  # TIER 3: COMPLEX - Heavy operations (synthesis, reports)
  complex:
    endpoints:
      - sonnet
    temperature: 0.7
    max_tokens: 32000
    reasoning_effort: high
    reasoning_budget: 8000
    tokens_per_minute: 100000
    rotation_strategy: priority
    fallback_on_429: true

# Agent configuration
agents:
  researcher:
    max_search_queries: 4
    max_search_results: 15      # Increased from 10 - more URL options
    max_urls_to_crawl: 10        # Increased from 3 - more content for citations
    content_preview_length: 3000
    content_storage_length: 15000  # Increased from 10000 - store more content
    max_previous_observations: 10
    page_contents_limit: 8000
    max_generated_queries: 3

  planner:
    max_plan_iterations: 3

  coordinator:
    max_clarification_rounds: 3
    enable_clarification: true

  synthesizer:
    max_report_length: 50000
    # Report length limits by research depth (min/max words, max tokens)
    report_limits:
      light:
        min_words: 800
        max_words: 1200
        max_tokens: 2000
      medium:
        min_words: 1200
        max_words: 2000
        max_tokens: 4000
      extended:
        min_words: 1200
        max_words: 3200
        max_tokens: 8000

  background:
    max_search_queries: 4
    max_results_per_query: 5
    max_total_results: 8

# =============================================================================
# Research Type Profiles (FR-100)
# =============================================================================
# Unified configuration for each research depth. Consolidates step limits,
# report limits, researcher settings, and citation verification overrides.
# Each type defines complete behavior for that research depth.
#
# Researcher modes:
#   - "classic": Single-pass researcher with fixed searches/crawls per step
#   - "react": ReAct loop where LLM controls tool calls with budget limit
research_types:
  light:
    # Step limits: quick overview with minimal research
    steps:
      min: 1
      max: 3
      prompt_guidance: "Quick overview with 1-3 focused steps. Prioritize speed over depth."

    # Report length limits
    report_limits:
      min_words: 800
      max_words: 1200
      max_tokens: 2000

    # Researcher configuration
    researcher:
      mode: classic        # Single-pass for speed
      max_search_queries: 2
      max_urls_to_crawl: 3
      max_tool_calls: 8    # ReAct fallback budget

    # Citation verification: lighter verification for quick research
    citation_verification:
      generation_mode: natural
      enable_numeric_qa_verification: false

  medium:
    # Step limits: balanced research covering key aspects
    steps:
      min: 3
      max: 6
      prompt_guidance: "Balanced research covering key aspects thoroughly. Aim for comprehensive coverage."

    # Report length limits
    report_limits:
      min_words: 1200
      max_words: 2000
      max_tokens: 4000

    # Researcher configuration
    researcher:
      mode: react          # ReAct for more intelligent search
      max_search_queries: 3  # Classic fallback
      max_urls_to_crawl: 5
      max_tool_calls: 12     # ReAct budget

    # Citation verification: standard verification
    citation_verification:
      generation_mode: natural

  extended:
    # Step limits: comprehensive deep research
    steps:
      min: 5
      max: 10
      prompt_guidance: "Comprehensive deep research. Multiple perspectives, thorough verification, detailed analysis."

    # Report length limits
    report_limits:
      min_words: 1500
      max_words: 3200
      max_tokens: 8000

    # Researcher configuration
    researcher:
      mode: react          # ReAct for deep research
      max_search_queries: 4  # Classic fallback
      max_urls_to_crawl: 8
      max_tool_calls: 20     # More budget for deep research

    # Citation verification: strict verification with numeric QA
    citation_verification:
      generation_mode: strict
      enable_numeric_qa_verification: true
      react_synthesis:
        max_tool_calls: 125          # Higher budget for comprehensive extended reports
        tool_budget_per_section: 20  # More budget per section

# Search configuration
search:
  brave:
    requests_per_second: 1.0
    default_result_count: 10
    freshness: pm  # pd=day, pw=week, pm=month, py=year

  # Domain whitelist/blacklist filtering
  # Supports wildcard patterns: *.gov, *.edu, news.*, *.example.*
  # Modes: "include" (whitelist only), "exclude" (blacklist only), "both" (whitelist + blacklist)
  domain_filter:
    mode: exclude  # Default: exclude (blacklist mode)

    # Domains to include (whitelist) - only used when mode is "include" or "both"
    # If set in include/both mode, ONLY these domains are allowed
    # include_domains:
    #   - "*.gov"
    #   - "*.edu"
    #   - "reuters.com"
    #   - "bbc.com"
    #   - "*.wikipedia.org"
    #   - "arxiv.org"

    # Domains to exclude (blacklist) - used when mode is "exclude" or "both"
    # These domains are always blocked
    exclude_domains: []
      # Examples of domains you might want to block:
      # - "*.ru"           # Russian domains
      # - "*.cn"           # Chinese domains
      # - "spam-site.com"  # Known spam sites

    # Log filtered URLs for debugging (default: false)
    log_filtered: false

# Rate limiting and retry configuration
rate_limiting:
  max_retries: 3                    # Max retry attempts before failing
  base_delay_seconds: 2.0           # Initial backoff delay
  max_delay_seconds: 60.0           # Maximum backoff delay
  backoff_strategy: exponential     # "exponential" (2^n) or "linear" (+n)
  jitter: true                      # Add random jitter to prevent thundering herd

# Truncation limits for consistency
truncation:
  log_preview: 200
  error_message: 500
  query_display: 100
  source_snippet: 300

# Citation verification configuration (6-stage pipeline)
#
# Per-depth overrides in research_types.*.citation_verification inherit from this
# global config. Only explicitly set fields override; unset fields inherit.
# Example: setting only `generation_mode: natural` in per-type inherits
# `synthesis_mode: react` from global.
citation_verification:
  # Master toggle for the feature
  enabled: true

  # Synthesis mode: controls the overall synthesis approach
  # - "interleaved": Current approach - evidence in context, [N] markers
  # - "react": ReAct-based - LLM uses tools to retrieve evidence before claims
  synthesis_mode: react

  # Generation mode for research reports (only applies when synthesis_mode=interleaved)
  # - "classical": Free-form prose with inline [Title](url) links
  #                Best text quality, uses existing synthesizer
  #                Skips verification stages 3-6 (no claim markers to verify)
  # - "natural": Light-touch [N] citations, balanced quality + verification
  #              Good text quality while maintaining verifiable citations
  #              Runs full verification pipeline (stages 3-6)
  # - "strict": Heavy [N] constraints, maximum citations (DEFAULT)
  #             Current behavior, every claim must cite evidence
  #             Runs full verification pipeline (stages 3-6)
  generation_mode: natural

  # ReAct synthesis configuration (only applies when synthesis_mode=react)
  react_synthesis:
    max_tool_calls: 75              # Total tool call budget (increased from 40)
    tool_budget_per_section: 15     # Budget per research step section
    retrieval_window_size: 3        # Sliding window for grounding inference
    grounding_threshold: 0.6        # Minimum similarity for grounded claim
    embedding_high_threshold: 0.7   # Auto-grounded above this
    embedding_low_threshold: 0.4    # Auto-ungrounded below this
    use_llm_judge_for_borderline: true  # Use LLM for 0.4-0.7 range
    enable_post_processing: true    # Polish pass for coherence
    use_sectioned_synthesis: false  # Disabled to use XML tag parsing in run_react_synthesis()

  # Stage toggles (only apply to "natural" and "strict" modes)
  enable_evidence_preselection: true
  enable_interleaved_generation: true
  enable_confidence_classification: true
  enable_citation_correction: true
  enable_numeric_qa_verification: true
  enable_verification_retrieval: false  # Optional additional search

  # Stage 1: Evidence Pre-Selection
  evidence_preselection:
    max_spans_per_source: 15
    min_span_length: 50
    max_span_length: 500
    relevance_threshold: 0.3
    numeric_content_boost: 0.2
    relevance_computation_method: hybrid  # semantic | keyword | hybrid
    # Chunking config for long sources (research papers, long articles)
    chunk_size: 8000           # Target size per chunk in characters
    chunk_overlap: 1000        # Overlap between chunks to avoid missing spans at boundaries
    max_chunks_per_source: 5   # Max chunks to process per source (limits LLM calls)

  # Stage 2: Interleaved Generation
  interleaved_generation:
    max_claims_per_section: 50
    min_evidence_similarity: 0.5
    retry_on_entailment_failure: true
    max_retries: 3

  # Stage 3: Confidence Classification
  confidence_classification:
    high_threshold: 0.6
    low_threshold: 0.50
    quote_match_bonus: 0.3
    hedging_word_penalty: 0.2
    estimation_method: embedding_similarity  # linguistic | embedding_similarity | hybrid

  # Stage 4: Isolated Verification
  isolated_verification:
    enable_nei_verdict: true
    verification_model_tier: analytical
    quick_verification_tier: simple

  # Stage 5: Citation Correction
  citation_correction:
    correction_method: keyword_semantic_hybrid
    lambda_weight: 0.8
    correction_threshold: 0.6
    allow_alternate_citations: true

  # Stage 6: Numeric QA Verification
  numeric_qa_verification:
    rounding_tolerance: 0.05
    answer_comparison_method: f1  # exact_match | f1 | lerc
    require_unit_match: true
    require_entity_match: true

  # Verification retrieval (when enabled)
  verification_retrieval:
    trigger_on_verdicts: [unsupported, nei]
    max_additional_searches: 2
    search_timeout_seconds: 3

  # Warning thresholds
  unsupported_claim_warning_threshold: 0.20
